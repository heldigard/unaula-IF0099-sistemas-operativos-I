---
marp: true
theme: default
paginate: true
header: 'IF0099 - Sistemas Operativos I | Unidad 8'
footer: 'UNAULA - IngenierÃ­a InformÃ¡tica - 2026-I'
---

# Clase 13: Sistemas Distribuidos
## Arquitecturas, Retos y Casos Reales

**Pregunta fundamental:** Â¿CÃ³mo hacemos que mÃºltiples computadores trabajen juntos como uno solo?

**Contexto:** Los sistemas que usamos diariamente (Google, WhatsApp, Netflix) son distribuidos

---

## Conceptos Clave de esta Clase

| Ãrea | Pregunta Fundamental | Ejemplo |
|------|---------------------|---------|
| **DefiniciÃ³n** | Â¿QuÃ© hace que un sistema sea distribuido? | MÃºltiples nodos = un sistema |
| **CAP** | Â¿QuÃ© compromisos existen entre consistencia, disponibilidad y particiones? | Solo 2 de 3 posibles |
| **ComunicaciÃ³n** | Â¿CÃ³mo se coordinan los nodos entre sÃ­? | RPC, mensajerÃ­a, REST |
| **Casos reales** | Â¿CÃ³mo funcionan Kubernetes, Cassandra, Netflix? | Veremos 5 sistemas reales |

<style>
section {
  font-size: 20px;
  overflow: hidden;
}
img {
  max-width: 70% !important;
  max-height: 50vh !important;
  object-fit: contain !important;
  height: auto !important;
  display: block !important;
  margin: 0 auto !important;
}
section h1 {
  font-size: 1.8em;
}
section h2 {
  font-size: 1.4em;
}
section h3 {
  font-size: 1.2em;
}
section ul, section ol {
  font-size: 0.9em;
  margin-left: 1em;
}
section li {
  margin-bottom: 0.3em;
}
section pre {
  font-size: 0.7em;
  max-height: 60vh;
  overflow-y: auto;
}
section code {
  font-size: 0.85em;
}
section p {
  margin: 0.5em 0;
}
/* Estilos para tablas responsivas */
section table {
  width: 100%;
  max-width: 100%;
  font-size: 0.85em;
  border-collapse: collapse;
  margin: 0.5em auto;
  table-layout: auto;
}
section th {
  background-color: #1e40af;
  color: white;
  padding: 0.4em 0.6em;
  text-align: left;
  font-size: 0.9em;
  border: 1px solid #ddd;
}
section td {
  padding: 0.4em 0.6em;
  border: 1px solid #ddd;
  vertical-align: top;
  word-wrap: break-word;
  font-size: 0.85em;
}
section tbody tr:nth-child(even) {
  background-color: #f8f9fa;
}
section tbody tr:hover {
  background-color: #e9ecef;
}
/* Asegurar que el contenido no desborde */
section {
  padding: 1em 2em;
  box-sizing: border-box;
}
/* Responsividad para tablas anchas */
@media screen and (max-width: 1280px) {
  section table {
    font-size: 0.75em;
  }
  section th, section td {
    padding: 0.3em 0.4em;
  }
}
</style>

---

## Objetivos de la Clase

Al finalizar esta clase, el estudiante serÃ¡ capaz de:

1. **Definir** quÃ© es un sistema distribuido y sus caracterÃ­sticas fundamentales
2. **Identificar** ventajas y desafÃ­os de los sistemas distribuidos
3. **Clasificar** los tipos de sistemas distribuidos segÃºn su arquitectura
4. **Explicar** el teorema CAP y sus implicaciones prÃ¡cticas
5. **Reconocer** modelos de comunicaciÃ³n y coordinaciÃ³n distribuida
6. **Analizar** casos reales de sistemas distribuidos modernos

**DuraciÃ³n:** 90 minutos

---

## Agenda

1. Conceptos bÃ¡sicos de sistemas distribuidos (15 min)
2. CaracterÃ­sticas y tipos de sistemas distribuidos (15 min)
3. Retos: sincronizaciÃ³n, fallos, consistencia (20 min)
4. Modelos de comunicaciÃ³n (10 min)
5. Casos reales: Kubernetes, Cassandra, GFS, Netflix (25 min)
6. Actividad prÃ¡ctica (5 min)

---

## 1. Â¿QuÃ© es un Sistema Distribuido?

### DefiniciÃ³n Formal

> Un **sistema distribuido** es un conjunto de computadores independientes que se presentan al usuario como un Ãºnico sistema coherente.

**Elementos clave:**
- **Computadores independientes:** Cada nodo tiene su propia CPU, memoria, SO
- **Se presentan como uno:** El usuario no ve la complejidad distribuida
- **Sistema coherente:** Comparte estado, coordina acciones

**AnalogÃ­a:**
- **Sistema NO distribuido:** Una tienda con un solo cajero
- **Sistema distribuido:** Una cadena de tiendas con mÃºltiples cajeros que comparten inventario

> **Insight:** La magia de los sistemas distribuidos es que **ocultan la complejidad** de la distribuciÃ³n al usuario.

---

### Ejemplos Cotidianos de Sistemas Distribuidos

**En tu dÃ­a a dÃ­a (sin que lo notes):**

| Servicio | Â¿QuÃ© hace distribuido? | Nodos involucrados |
|----------|------------------------|-------------------|
| ğŸŒ **Google** | BÃºsqueda en milisegundos | Miles de servidores globales |
| ğŸ“± **WhatsApp** | Mensajes sincronizados | Servidores en mÃºltiples regiones |
| ğŸ® **Juegos online** | Jugadores conectados | Clientes + servidores de juego |
| ğŸ’° **Bitcoin** | Transacciones verificadas | Miles de nodos blockchain |
| ğŸ“§ **Email** | Correo global | Servidores SMTP/IMAP distribuidos |

ğŸ’¡ **La nube (AWS, Azure, Google Cloud) son sistemas distribuidos masivos.**

---

### CaracterÃ­sticas Fundamentales

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚           CARACTERÃSTICAS DE SISTEMAS DISTRIBUIDOS          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                             â”‚
â”‚  ğŸ”¹ CONCURRENCIA           ğŸ”¹ FALTA DE RELOJ GLOBAL        â”‚
â”‚     MÃºltiples actividades      No hay "hora exacta" Ãºnica   â”‚
â”‚     simultÃ¡neas en diferentes  Cada nodo tiene su reloj     â”‚
â”‚     nodos                                                     â”‚
â”‚     â†’ Problemas de sincronizaciÃ³n                           â”‚
â”‚                                                             â”‚
â”‚  ğŸ”¹ FALLOS PARCIALES       ğŸ”¹ TRANSPARENCIA                â”‚
â”‚     Un nodo puede fallar       Se ve como un solo sistema   â”‚
â”‚     sin afectar todo           El usuario no ve la          â”‚
â”‚                                complejidad distribuida      â”‚
â”‚     â†’ DetecciÃ³n difÃ­cil                                  â”‚
â”‚                                                             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Implicaciones prÃ¡cticas:**
| CaracterÃ­stica | DesafÃ­o | SoluciÃ³n tÃ­pica |
|----------------|---------|-----------------|
| Concurrencia | Race conditions | SemÃ¡foros, locks distribuidos |
| Sin reloj global | Eventos desordenados | Relojes lÃ³gicos (Lamport) |
| Fallos parciales | Â¿Nodo lento o caÃ­do? | Heartbeat, timeouts |
| Transparencia | Complejidad oculta | Abstracciones (RPC) |

---

## 2. Tipos de Sistemas Distribuidos

### ClasificaciÃ³n por Arquitectura

<div style="display: flex; gap: 15px; font-size: 0.9em;">

<div style="flex: 1;">

### ğŸ–¥ï¸ **Cliente-Servidor**
- Servidores centralizados
- Clientes solicitan servicios
- **Ejemplos:** Web, Bases de datos
- **Ventaja:** Simple de gestionar
- **Desventaja:** Punto Ãºnico de fallo

```
Cliente â†â†’ Servidor
```

</div>

<div style="flex: 1;">

### ğŸ”„ **Peer-to-Peer (P2P)**
- Todos los nodos son iguales
- Sin servidor central
- **Ejemplos:** BitTorrent, Blockchain
- **Ventaja:** Escalabilidad
- **Desventaja:** CoordinaciÃ³n compleja

```
Nodo â†â†’ Nodo â†â†’ Nodo
```

</div>

<div style="flex: 1;">

### â˜ï¸ **ClÃºster/Grid**
- Nodos dedicados al cÃ³mputo
- Alta disponibilidad
- **Ejemplos:** HPC, Kubernetes
- **Ventaja:** Alto rendimiento
- **Desventaja:** Costo de infraestructura

```
Master â†â†’ [Nodos]
```

</div>

</div>

**ComparaciÃ³n:**
| Arquitectura | Escalabilidad | Complejidad | Caso de uso |
|--------------|---------------|-------------|-------------|
| Cliente-Servidor | Media | Baja | Web tradicional |
| P2P | Muy alta | Alta | File sharing |
| ClÃºster | Alta | Media | HPC, microservicios |

---

## 3. Retos de los Sistemas Distribuidos

### El Teorema CAP

> **CAP:** Consistency (Consistencia) - Availability (Disponibilidad) - Partition Tolerance (Tolerancia a particiones)

**Principio fundamental:** En un sistema distribuido, solo puedes garantizar **2 de las 3** propiedades simultÃ¡neamente.

```
                    CAP
                   / | \
                  /  |  \
                 /   |   \
           Consistency  Partition
                 \   |   /
                  \  |  /
                   \ | /
                 Availability
```

**Â¿QuÃ© significa cada propiedad?**
| Propiedad | Significado | Ejemplo |
|-----------|-------------|---------|
| **C** - Consistencia | Todos los nodos ven los mismos datos al mismo tiempo | Transferencia: debitado = acreditado simultÃ¡neamente |
| **A** - Disponibilidad | Todo nodo responde (aunque con datos viejos) | Siempre puedes leer/escribir |
| **P** - Particionamiento | El sistema funciona aunque la red falle | Mensajes entre nodos pueden perderse |

> **Insight:** En sistemas distribuidos reales, **P es inevitable** (las redes fallan). AsÃ­ que la elecciÃ³n real es entre **CP** (consistencia) o **AP** (disponibilidad).

---

### Elecciones de DiseÃ±o CAP

| Sistema | Elige | Significado | CuÃ¡ndo usarlo |
|---------|-------|-------------|---------------|
| **CP** | Consistencia + Particionamiento | Datos consistentes, pero puede no estar disponible | Bancos, inventario, configuraciÃ³n |
| **AP** | Disponibilidad + Particionamiento | Siempre responde, pero datos pueden ser inconsistentes | Redes sociales, caching, logs |
| **CA** | Consistencia + Disponibilidad | Solo en sistemas NO distribuidos | Base de datos single-node |

**Ejemplos reales:**
| Sistema | ElecciÃ³n | RazÃ³n |
|---------|----------|-------|
| **etcd** (Kubernetes) | CP | La configuraciÃ³n debe ser consistente |
| **Cassandra** | AP | Escrituras masivas, prioriza disponibilidad |
| **MySQL (replicado)** | CP | Datos financieros requieren consistencia |
| **Redis Cluster** | AP | Caching, preferible disponibilidad |

> **Trade-off:** Consistencia vs Latencia. Mayor consistencia = mayor latencia.

---

### Otros Retos Importantes

<div style="display: flex; gap: 15px; font-size: 0.85em;">

<div style="flex: 1;">

#### âš ï¸ **Fallos Parciales**
- Un nodo falla, otros continÃºan
- DifÃ­cil de detectar (Â¿lento o caÃ­do?)
- Requiere mecanismos de heartbeat
- **SoluciÃ³n:** Timeouts, reintentos

#### ğŸ”’ **Consenso Distribuido**
- Â¿CÃ³mo ponernos de acuerdo?
- Algoritmos: Raft, Paxos
- ElecciÃ³n de lÃ­der
- **SoluciÃ³n:** etcd, ZooKeeper

</div>

<div style="flex: 1;">

#### ğŸ• **SincronizaciÃ³n**
- No hay reloj global exacto
- Eventos pueden llegar desordenados
- Relojes lÃ³gicos (Lamport timestamps)
- **SoluciÃ³n:** Vector clocks, NTP

#### ğŸ“Š **Consistencia de Datos**
- RÃ©plicas pueden divergir
- Modelos: eventual, fuerte, causal
- Compromiso consistencia vs rendimiento
- **SoluciÃ³n:** Quorum, version vectors

</div>

</div>

**Resumen de retos y soluciones:**
| Reto | SoluciÃ³n | TecnologÃ­as |
|------|----------|-------------|
| Fallos parciales | Heartbeat + timeout | Consul, ZooKeeper |
| Consenso | Algoritmos Raft/Paxos | etcd, Consul |
| SincronizaciÃ³n | Relojes lÃ³gicos | Lamport timestamps |
| Consistencia | Modelos de consistencia | Cassandra (eventual), etcd (fuerte) |

---

## 4. Modelos de ComunicaciÃ³n

### Mecanismos de ComunicaciÃ³n entre Nodos

| Modelo | DescripciÃ³n | Caso de Uso | Ejemplo TecnologÃ­a |
|--------|-------------|-------------|-------------------|
| **RPC** | Llamada a funciÃ³n remota como si fuera local | Servicios internos | gRPC, Thrift |
| **MensajerÃ­a** | Colas de mensajes asÃ­ncronas | Procesamiento por lotes | Kafka, RabbitMQ |
| **REST** | HTTP + JSON/XML | APIs pÃºblicas | API REST |
| **Streaming** | Flujo continuo de datos | Tiempo real | WebSocket, Flink |
| **Shared Memory** | Memoria compartida entre procesos | Alto rendimiento | SHM, mmap |

**ComparaciÃ³n:**
| Modelo | Latencia | Acoplamiento | Escalabilidad |
|--------|----------|--------------|---------------|
| RPC | Baja | Alto | Media |
| MensajerÃ­a | Media | Bajo | Alta |
| REST | Alta | Medio | Alta |
| Streaming | Muy baja | Bajo | Muy alta |

---

### ComparaciÃ³n: SÃ­ncrono vs AsÃ­ncrono

<div style="display: flex; gap: 20px;">

<div style="flex: 1;">

#### ğŸ”„ **SÃ­ncrono (RPC)**
```
Cliente â”€â”€requestâ”€â”€â–º Servidor
   â”‚â—„â”€â”€â”€â”€responseâ”€â”€â”€â”€â”˜
   â”‚
   â–¼
Espera bloqueada
```
- **Ventaja:** Simple de razonar
- **Desventaja:** Acoplamiento temporal
- **Uso:** Consultas que requieren respuesta inmediata

</div>

<div style="flex: 1;">

#### ğŸ“¨ **AsÃ­ncrono (Mensajes)**
```
Productor â”€â”€msgâ”€â”€â–º Cola â”€â”€msgâ”€â”€â–º Consumidor
     â”‚                            â”‚
     â””â”€â”€â”€â”€â–º ContinÃºa              â””â”€â”€â–º Procesa cuando puede
```
- **Ventaja:** Desacoplamiento, resiliencia
- **Desventaja:** Complejidad de manejo
- **Uso:** Procesamiento por lotes, eventos

</div>

</div>

**Ejemplos prÃ¡cticos:**
| PatrÃ³n | Caso de uso | TecnologÃ­as |
|--------|-------------|-------------|
| SÃ­ncrono | API REST, consultas a BD | HTTP, gRPC |
| AsÃ­ncrono | Procesamiento de eventos | Kafka, RabbitMQ |
| HÃ­brido | Microservicios | Saga pattern, event sourcing |

---

## 5. Casos Reales de Sistemas Distribuidos

### 5.1 Kubernetes - OrquestaciÃ³n de Contenedores

**Â¿QuÃ© es?**
Sistema distribuido para gestionar contenedores Docker en mÃºltiples mÃ¡quinas.

**Problema que resuelve:** Gestionar miles de contenedores distribuidos en mÃºltiples mÃ¡quinas

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚          KUBERNETES CLUSTER             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                         â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚   Master     â”‚â—„â”€â”€â–ºâ”‚    etcd      â”‚  â”‚
â”‚  â”‚   (Control   â”‚    â”‚  (Registro   â”‚  â”‚
â”‚  â”‚    Plane)    â”‚    â”‚ Distribuido) â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚         â”‚                               â”‚
â”‚    â”Œâ”€â”€â”€â”€â”´â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”       â”‚
â”‚    â”‚         â”‚        â”‚        â”‚       â”‚
â”‚  â”Œâ”€â–¼â”€â”€â”   â”Œâ”€â–¼â”€â”€â”  â”Œâ”€â–¼â”€â”€â”  â”Œâ”€â–¼â”€â”€â”     â”‚
â”‚  â”‚Nodeâ”‚   â”‚Nodeâ”‚  â”‚Nodeâ”‚  â”‚Nodeâ”‚     â”‚
â”‚  â”‚  1 â”‚   â”‚  2 â”‚  â”‚  3 â”‚  â”‚  4 â”‚     â”‚
â”‚  â””â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”˜     â”‚
â”‚                                         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**CaracterÃ­sticas clave:**
- **Auto-recuperaciÃ³n:** Si un nodo falla, reinicia pods en otro nodo
- **Escalado horizontal:** AÃ±ade nodos automÃ¡ticamente segÃºn carga
- **Rolling updates:** Actualiza sin downtime
- **Service discovery:** Pods se encuentran automÃ¡ticamente

---

### Componentes de Kubernetes

<div style="display: flex; gap: 15px; font-size: 0.85em;">

<div style="flex: 1;">

#### **Master Node (Control Plane)**
- **API Server:** Punto de entrada para todas las operaciones
- **Scheduler:** Decide en quÃ© nodo ejecutar cada pod
- **Controller Manager:** Mantiene el estado deseado
- **etcd:** Base de datos distribuida de configuraciÃ³n

</div>

<div style="flex: 1;">

#### **Worker Nodes**
- **Kubelet:** Agente que ejecuta containers en cada nodo
- **Kube-proxy:** Maneja networking y balanceo
- **Container Runtime:** Docker, containerd

</div>

</div>

**CaracterÃ­sticas Distribuidas:**
- âœ… **ReplicaciÃ³n:** Copia automÃ¡tica de pods en mÃºltiples nodos
- âœ… **Auto-recuperaciÃ³n:** Si un nodo falla, mueve pods a otro
- âœ… **Escalado horizontal:** AÃ±ade/quita nodos dinÃ¡micamente

---

### 5.2 Apache Cassandra - Base de Datos Distribuida

**Arquitectura sin Maestro (Masterless):**

**Problema que resuelve:** Escrituras masivas (millones/segundo) con alta disponibilidad

```
         Nodo A
         /    \
       /        \
    Nodo B â”€â”€â”€ Nodo C
       \        /
        \      /
         Nodo D
```

**CaracterÃ­sticas:**
| CaracterÃ­stica | DescripciÃ³n |
|----------------|-------------|
| **Sin SPOF** | Todos los nodos son iguales, no hay maestro |
| **ReplicaciÃ³n configurable** | Datos en N nodos (ej: N=3) |
| **Consistencia eventual** | Escribe en algunos, lee de algunos |
| **Particionamiento** | Hash ring divide datos entre nodos |
| **Multi-datacenter** | RÃ©plicas geogrÃ¡ficamente distribuidas |

**ElecciÃ³n CAP:** Cassandra elige **AP** (Disponibilidad + Particionamiento)

---

### Cassandra: Ejemplo de Escritura

```python
# Cliente escribe "usuario123" con RF=3 (Replication Factor)
cassandra.insert("usuarios", "usuario123", datos)

# Cassandra automÃ¡ticamente:
# 1. Calcula hash(usuario123) = 0x8A3F...
# 2. Ubica en el anillo: Nodo B es responsable
# 3. Replica en Nodos C y D (siguientes en el anillo)
# 4. Escritura exitosa si 2 de 3 nodos confirman (Quorum)
```

**ElecciÃ³n CAP:** Cassandra elige **AP** (Disponibilidad + Particionamiento)
â†’ Eventual consistency para mÃ¡xima disponibilidad

---

### 5.3 Google File System (GFS) / HDFS

**Problema que resuelve:** Almacenar archivos de **petabytes** en miles de mÃ¡quinas comunes

**Casos de uso:**
- Google: Indexar toda la web
- Hadoop: Procesar Big Data con MapReduce

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚           GFS MASTER                   â”‚
â”‚  â€¢ Almacena metadata (nombres, etc)   â”‚
â”‚  â€¢ Coordina operaciones                â”‚
â”‚  â€¢ Single point of failure (en GFS)   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
    â”Œâ”€â”€â”€â”€â”´â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚         â”‚        â”‚        â”‚
â”Œâ”€â”€â”€â–¼â”€â”€â”€â” â”Œâ”€â”€â–¼â”€â”€â”€â” â”Œâ”€â”€â–¼â”€â”€â”€â” â”Œâ”€â”€â–¼â”€â”€â”€â”
â”‚Chunk  â”‚ â”‚Chunk â”‚ â”‚Chunk â”‚ â”‚Chunk â”‚
â”‚Server â”‚ â”‚Serverâ”‚ â”‚Serverâ”‚ â”‚Serverâ”‚
â”‚   1   â”‚ â”‚  2   â”‚ â”‚  3   â”‚ â”‚  4   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”˜
  Datos    Datos    Datos    Datos
  (64MB)   (64MB)   (64MB)   (64MB)
```

**CaracterÃ­sticas clave:**
- **Chunks grandes:** 64-128 MB (reduce overhead de metadata)
- **ReplicaciÃ³n automÃ¡tica:** 3 copias por defecto
- **Comodidad over consistencia:** Optimizado para appends, no random writes

---

### GFS/HDFS: Detalles TÃ©cnicos

**Componentes:**

| Componente | FunciÃ³n | En HDFS |
|------------|---------|---------|
| **Master** | Metadatos, coordina operaciones | NameNode |
| **Chunk Servers** | Almacenan datos reales | DataNodes |

**TamaÃ±o de Chunks:**
- GFS: 64 MB (mÃ¡s grande que bloques tradicionales)
- HDFS: 128 MB (por defecto)
- **Â¿Por quÃ© tan grandes?** Reduce overhead de metadata

**ReplicaciÃ³n:**
Cada chunk se replica en 3 servidores diferentes. Si uno falla, Master ordena replicar desde otro.

---

### 5.4 Netflix - CDN Distribuido

**Problema:** Entregar video HD a 200M usuarios simultÃ¡neos sin lag

**SoluciÃ³n: Open Connect (CDN propio)**

```
        Usuario en MedellÃ­n
              â”‚
              â†“
      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
      â”‚   CDN Cache  â”‚  â† Servidor en MedellÃ­n (local)
      â”‚   Colombia   â”‚     Tiene pelÃ­culas populares
      â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
             â”‚ (si no estÃ¡)
             â†“
      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
      â”‚  CDN Regionalâ”‚  â† Servidor en Miami
      â”‚ LatinoamÃ©ricaâ”‚
      â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
             â”‚ (si no estÃ¡)
             â†“
      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
      â”‚  Origen AWS  â”‚  â† Servidor origen en Virginia
      â”‚   EE.UU.     â”‚
      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**JerarquÃ­a de caches:**
| Nivel | UbicaciÃ³n | Almacenamiento | TrÃ¡fico |
|-------|-----------|----------------|---------|
| **Edge Cache** | Ciudades grandes (ISP local) | 20-40 TB | 90% |
| **Regional Cache** | Puntos de intercambio | 100+ TB | 9% |
| **Origin (AWS)** | Virginia | Todo el catÃ¡logo | 1% |

**Optimizaciones clave:**
- **Pre-caching:** PelÃ­culas populares se cargan durante la noche
- **Smart routing:** DNS inteligente dirige al servidor mÃ¡s cercano
- **Adaptive streaming:** Calidad se ajusta segÃºn ancho de banda

---

### Netflix: JerarquÃ­a de Caches

| Nivel | UbicaciÃ³n | Almacenamiento | TrÃ¡fico |
|-------|-----------|----------------|---------|
| **Edge Cache** | Ciudades grandes (ISP local) | 20-40 TB | 90% |
| **Regional Cache** | Puntos de intercambio | 100+ TB | 9% |
| **Origin (AWS)** | Virginia | Todo el catÃ¡logo | 1% |

**Optimizaciones:**
- **Pre-caching:** PelÃ­culas populares se cargan durante la noche
- **Smart routing:** DNS inteligente dirige al servidor mÃ¡s cercano
- **Adaptive streaming:** Calidad se ajusta segÃºn ancho de banda

**MÃ©tricas:**
- Latencia promedio: **<50 ms**
- Throughput: **100 Gbps** por servidor edge

---

### 5.5 WhatsApp - Sistema de MensajerÃ­a

**Problema:** 2+ mil millones de usuarios, 50M mensajes/segundo

**Arquitectura (Simplificada):**

```
Usuario A (Colombia)             Usuario B (JapÃ³n)
      â”‚                                â”‚
      â†“                                â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Servidor â”‚                    â”‚ Servidor â”‚
â”‚ Colombia â”‚â”€â”€â”€â”€SincronizaciÃ³nâ”€â”€â”‚  JapÃ³n   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
      â”‚                                â”‚
      â””â”€â”€â”€â”€â”€â”€â”€â”€â–º Ejabberd â—„â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
              (Protocolo XMPP)
```

**TecnologÃ­a:**
| Componente | TecnologÃ­a | RazÃ³n |
|------------|------------|-------|
| **Lenguaje** | Erlang | DiseÃ±ado para sistemas distribuidos |
| **Modelo** | Actor model | Cada conversaciÃ³n = proceso ligero |
| **Capacidad** | 50M mensajes/segundo | Escalabilidad masiva |
| **Base de datos** | Mnesia | BD distribuida en Erlang |

**GarantÃ­as:**
| GarantÃ­a | DescripciÃ³n |
|----------|-------------|
| **Entrega garantizada** | Aunque receptor estÃ© offline |
| **Ordenamiento** | Mensajes llegan en orden |
| **Cifrado E2E** | Solo emisor y receptor pueden leer |

**ElecciÃ³n CAP:** WhatsApp elige **CP** (consistencia es crÃ­tica para mensajerÃ­a)

---

## ComparaciÃ³n de Estrategias

| Sistema | Tipo | CAP | Caso de Uso Principal |
|---------|------|-----|----------------------|
| **Kubernetes** | OrquestaciÃ³n | CP (etcd) | GestiÃ³n de containers |
| **Cassandra** | Base de datos | AP | Escrituras masivas, alta disponibilidad |
| **GFS/HDFS** | Almacenamiento | CP | Big Data, procesamiento batch |
| **Netflix CDN** | DistribuciÃ³n de contenido | AP | Streaming de video |
| **WhatsApp** | MensajerÃ­a | CP | ComunicaciÃ³n en tiempo real |

---

## Actividad PrÃ¡ctica (10 min)

### En parejas, respondan:

1. **Identificar:** Dar un ejemplo de sistema distribuido en su vida diaria (diferente a los vistos en clase)

2. **Analizar:** Para ese sistema, identificar:
   - Â¿CuÃ¡l es el problema que resuelve la distribuciÃ³n?
   - Â¿QuÃ© tipo de arquitectura tiene?
   - Â¿QuÃ© retos enfrenta (consistencia, disponibilidad, particiones)?

3. **Discutir:** Â¿Por quÃ© creen que WhatsApp eligiÃ³ CP en lugar de AP?

---

## Resumen de la Clase

| Concepto | Idea Clave | Ejemplo |
|----------|------------|---------|
| **Sistema Distribuido** | MÃºltiples nodos = un solo sistema | Google, WhatsApp, Netflix |
| **CAP** | Solo 2 de 3: C, A, P | CP (etcd) vs AP (Cassandra) |
| **Tipos** | Cliente-Servidor, P2P, ClÃºster | Web, BitTorrent, K8s |
| **ComunicaciÃ³n** | RPC, MensajerÃ­a, REST | gRPC, Kafka, HTTP |
| **Retos** | Fallos parciales, consistencia, sincronizaciÃ³n | Heartbeat, consenso |

### Sistemas Analizados:

| Sistema | Tipo | CAP | Caso de uso |
|---------|------|-----|-------------|
| **Kubernetes** | OrquestaciÃ³n | CP (etcd) | GestiÃ³n de containers |
| **Cassandra** | Base de datos | AP | Escrituras masivas |
| **GFS/HDFS** | Almacenamiento | CP | Big Data, batch |
| **Netflix CDN** | DistribuciÃ³n contenido | AP | Streaming video |
| **WhatsApp** | MensajerÃ­a | CP | Tiempo real |

**Puntos clave:**
1. **P es inevitable:** Las redes fallan, todos los sistemas distribuidos deben tolerar particiones
2. **Trade-off:** Consistencia vs Disponibilidad vs Latencia (elige 2)
3. **ComunicaciÃ³n:** SÃ­ncrono (simple) vs AsÃ­ncrono (escalable)
4. **No silver bullet:** Cada sistema optimiza para su caso de uso

---

## PrÃ³xima Clase

### Clase 14: Programas de AplicaciÃ³n e Interfaces

- Llamadas al sistema en profundidad
- APIs del SO
- System calls en Linux vs Windows
- Ejemplos prÃ¡cticos con strace

**Â¡Nos vemos!**

---

## Recursos Adicionales

### Para profundizar:
- **Libro:** "Designing Data-Intensive Applications" - Martin Kleppmann
- **Paper:** "The Google File System" - Sanjay Ghemawat et al.
- **Curso:** MIT 6.824 - Distributed Systems

### Herramientas para experimentar:
- **Minikube:** Kubernetes local en tu laptop
- **Docker Swarm:** Alternativa ligera a Kubernetes
- **Consul:** Service discovery y configuraciÃ³n distribuida
